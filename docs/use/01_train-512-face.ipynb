{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\kaggle\\pytorch-book\\apps\n"
     ]
    }
   ],
   "source": [
    "cd ../../apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import time\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "from tools.file import mkdir\n",
    "from utils.torch_loader_all import Loader\n",
    "from tools.toml import load_option\n",
    "from app import  init, mask_op, array2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root': 'E:/kaggle/datasets/CelebA/Img/img_align_celeba', 'mask': 'D:/kaggle/dataset/mask/testing_mask_dataset', 'fine_size': 512, 'batch_size': 1}\n"
     ]
    }
   ],
   "source": [
    "opt = load_option('../origin/train-512-face.toml')\n",
    "print(opt)\n",
    "loader = Loader(**opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "---------- Networks initialized -------------\n",
      "UnetGeneratorCSA(\n",
      "  (model): UnetSkipConnectionBlock_3(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): UnetSkipConnectionBlock_3(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "          (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (6): UnetSkipConnectionBlock_3(\n",
      "            (model): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "              (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (6): CSA(\n",
      "                (model): Sequential(\n",
      "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                  (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (5): CSA_model(threshold: 0.3125 ,triple_weight 1)\n",
      "                  (6): InnerCos(skip: True ,strength: 1)\n",
      "                  (7): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (8): UnetSkipConnectionBlock_3(\n",
      "                    (model): Sequential(\n",
      "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                      (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                      (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (6): UnetSkipConnectionBlock_3(\n",
      "                        (model): Sequential(\n",
      "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                          (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (6): UnetSkipConnectionBlock_3(\n",
      "                            (model): Sequential(\n",
      "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                              (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                              (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (6): UnetSkipConnectionBlock_3(\n",
      "                                (model): Sequential(\n",
      "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                                  (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                                  (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (6): UnetSkipConnectionBlock_3(\n",
      "                                    (model): Sequential(\n",
      "                                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                                      (2): ReLU(inplace=True)\n",
      "                                      (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                    )\n",
      "                                  )\n",
      "                                  (7): ReLU(inplace=True)\n",
      "                                  (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                                  (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (10): ReLU(inplace=True)\n",
      "                                  (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                )\n",
      "                              )\n",
      "                              (7): ReLU(inplace=True)\n",
      "                              (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                              (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (10): ReLU(inplace=True)\n",
      "                              (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                            )\n",
      "                          )\n",
      "                          (7): ReLU(inplace=True)\n",
      "                          (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                          (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (10): ReLU(inplace=True)\n",
      "                          (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                        )\n",
      "                      )\n",
      "                      (7): ReLU(inplace=True)\n",
      "                      (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (10): ReLU(inplace=True)\n",
      "                      (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (9): InnerCos2(skip: True ,strength: 1)\n",
      "                  (10): ReLU(inplace=True)\n",
      "                  (11): ConvTranspose2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (12): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (13): ReLU(inplace=True)\n",
      "                  (14): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (15): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                )\n",
      "              )\n",
      "              (7): ReLU(inplace=True)\n",
      "              (8): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (9): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (10): ReLU(inplace=True)\n",
      "              (11): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (12): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (7): ReLU(inplace=True)\n",
      "          (8): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (9): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (10): ReLU(inplace=True)\n",
      "          (11): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (12): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): ConvTranspose2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 77692291\n",
      "UnetGenerator(\n",
      "  (model): UnetSkipConnectionBlock(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): UnetSkipConnectionBlock(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (3): UnetSkipConnectionBlock(\n",
      "            (model): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (3): UnetSkipConnectionBlock(\n",
      "                (model): Sequential(\n",
      "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (3): UnetSkipConnectionBlock(\n",
      "                    (model): Sequential(\n",
      "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (3): UnetSkipConnectionBlock(\n",
      "                        (model): Sequential(\n",
      "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (3): UnetSkipConnectionBlock(\n",
      "                            (model): Sequential(\n",
      "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (3): UnetSkipConnectionBlock(\n",
      "                                (model): Sequential(\n",
      "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (2): ReLU(inplace=True)\n",
      "                                  (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                )\n",
      "                              )\n",
      "                              (4): ReLU(inplace=True)\n",
      "                              (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                            )\n",
      "                          )\n",
      "                          (4): ReLU(inplace=True)\n",
      "                          (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                        )\n",
      "                      )\n",
      "                      (4): ReLU(inplace=True)\n",
      "                      (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (4): ReLU(inplace=True)\n",
      "                  (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                )\n",
      "              )\n",
      "              (4): ReLU(inplace=True)\n",
      "              (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (4): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 54419459\n",
      "NLayerDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 2766529\n",
      "PFDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 10487296\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CSA-512-face'\n",
    "beta = 1\n",
    "base_opt = load_option('../options/base512.toml')\n",
    "model_opt = load_option('../options/train-new.toml')\n",
    "model = init(model_name, beta, model_opt, base_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设定\n",
    "## 固定参数\n",
    "epochs = 500\n",
    "display_freq = 49\n",
    "save_epoch_freq = 1\n",
    "\n",
    "## 模型参数\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "\n",
    "model_name = f'CSA-crop-{alpha}-{beta}'\n",
    "image_save_dir = model.save_dir / 'images'\n",
    "mkdir(image_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch/total_steps/alpha-beta: 0/100/1-1 {'G_GAN': 5.674766540527344, 'G_L1': 82.69174194335938, 'D': 0.8737938404083252, 'F': 0.11914195865392685}\n",
      "Epoch/total_steps/alpha-beta: 0/200/1-1 {'G_GAN': 6.374797821044922, 'G_L1': 94.81090545654297, 'D': 0.49556198716163635, 'F': 0.0632593184709549}\n",
      "Epoch/total_steps/alpha-beta: 0/300/1-1 {'G_GAN': 5.32965087890625, 'G_L1': 53.254173278808594, 'D': 0.8827108144760132, 'F': 0.036601416766643524}\n",
      "Epoch/total_steps/alpha-beta: 0/400/1-1 {'G_GAN': 5.552875995635986, 'G_L1': 72.80084228515625, 'D': 0.9750968217849731, 'F': 0.1065833568572998}\n",
      "Epoch/total_steps/alpha-beta: 0/500/1-1 {'G_GAN': 6.736172676086426, 'G_L1': 52.51408386230469, 'D': 0.4093303084373474, 'F': 0.025163184851408005}\n",
      "Epoch/total_steps/alpha-beta: 0/600/1-1 {'G_GAN': 7.541547775268555, 'G_L1': 112.79335021972656, 'D': 0.12005992233753204, 'F': 0.01236003264784813}\n",
      "Epoch/total_steps/alpha-beta: 0/700/1-1 {'G_GAN': 6.069731712341309, 'G_L1': 47.136253356933594, 'D': 0.7534974813461304, 'F': 0.020309582352638245}\n",
      "Epoch/total_steps/alpha-beta: 0/800/1-1 {'G_GAN': 5.450955390930176, 'G_L1': 65.66997528076172, 'D': 0.8705061674118042, 'F': 0.060515161603689194}\n",
      "Epoch/total_steps/alpha-beta: 0/900/1-1 {'G_GAN': 6.46990966796875, 'G_L1': 75.23210144042969, 'D': 0.5232571363449097, 'F': 0.013653963804244995}\n",
      "Epoch/total_steps/alpha-beta: 0/1000/1-1 {'G_GAN': 6.787680625915527, 'G_L1': 50.51403045654297, 'D': 0.5192381143569946, 'F': 0.04075857624411583}\n",
      "Epoch/total_steps/alpha-beta: 0/1100/1-1 {'G_GAN': 6.793991565704346, 'G_L1': 49.92967224121094, 'D': 0.2963847517967224, 'F': 0.0138858025893569}\n",
      "Epoch/total_steps/alpha-beta: 0/1200/1-1 {'G_GAN': 6.908201694488525, 'G_L1': 46.24758529663086, 'D': 0.4864062964916229, 'F': 0.04695504158735275}\n",
      "Epoch/total_steps/alpha-beta: 0/1300/1-1 {'G_GAN': 7.270747184753418, 'G_L1': 39.49330520629883, 'D': 0.31095367670059204, 'F': 0.01762988604605198}\n",
      "Epoch/total_steps/alpha-beta: 0/1400/1-1 {'G_GAN': 7.141920566558838, 'G_L1': 90.7420883178711, 'D': 0.6246428489685059, 'F': 0.01644831895828247}\n",
      "Epoch/total_steps/alpha-beta: 0/1500/1-1 {'G_GAN': 7.252217769622803, 'G_L1': 80.00102233886719, 'D': 0.35810133814811707, 'F': 0.009534837678074837}\n",
      "Epoch/total_steps/alpha-beta: 0/1600/1-1 {'G_GAN': 6.656037330627441, 'G_L1': 78.57904815673828, 'D': 0.2720087170600891, 'F': 0.07613863795995712}\n",
      "Epoch/total_steps/alpha-beta: 0/1700/1-1 {'G_GAN': 6.747368812561035, 'G_L1': 53.054107666015625, 'D': 0.3349810242652893, 'F': 0.014762762933969498}\n",
      "Epoch/total_steps/alpha-beta: 0/1800/1-1 {'G_GAN': 7.704248428344727, 'G_L1': 49.09436798095703, 'D': 0.4437968134880066, 'F': 0.00922537874430418}\n",
      "Epoch/total_steps/alpha-beta: 0/1900/1-1 {'G_GAN': 7.979488372802734, 'G_L1': 38.44279479980469, 'D': 0.04135489463806152, 'F': 0.018109498545527458}\n",
      "Epoch/total_steps/alpha-beta: 0/2000/1-1 {'G_GAN': 8.089262962341309, 'G_L1': 29.569683074951172, 'D': 0.4374288320541382, 'F': 0.017628138884902}\n",
      "Epoch/total_steps/alpha-beta: 0/2100/1-1 {'G_GAN': 7.554396152496338, 'G_L1': 56.426353454589844, 'D': 0.5255504846572876, 'F': 0.012429237365722656}\n",
      "Epoch/total_steps/alpha-beta: 0/2200/1-1 {'G_GAN': 6.848667144775391, 'G_L1': 77.50362396240234, 'D': 0.3149612545967102, 'F': 0.01767728291451931}\n",
      "Epoch/total_steps/alpha-beta: 0/2300/1-1 {'G_GAN': 7.116144180297852, 'G_L1': 66.12065124511719, 'D': 0.15158146619796753, 'F': 0.01847725175321102}\n",
      "Epoch/total_steps/alpha-beta: 0/2400/1-1 {'G_GAN': 7.701614856719971, 'G_L1': 50.05036544799805, 'D': 0.35271155834198, 'F': 0.013561561703681946}\n",
      "Epoch/total_steps/alpha-beta: 0/2500/1-1 {'G_GAN': 8.142476081848145, 'G_L1': 56.733131408691406, 'D': 0.09474793076515198, 'F': 0.029223527759313583}\n",
      "Epoch/total_steps/alpha-beta: 0/2600/1-1 {'G_GAN': 7.383360862731934, 'G_L1': 66.50104522705078, 'D': 0.17739753425121307, 'F': 0.008837783709168434}\n",
      "Epoch/total_steps/alpha-beta: 0/2700/1-1 {'G_GAN': 8.906221389770508, 'G_L1': 34.362144470214844, 'D': 0.382310688495636, 'F': 0.016032561659812927}\n",
      "Epoch/total_steps/alpha-beta: 0/2800/1-1 {'G_GAN': 6.245453357696533, 'G_L1': 51.14915466308594, 'D': 0.5112225413322449, 'F': 0.012845803052186966}\n",
      "Epoch/total_steps/alpha-beta: 0/2900/1-1 {'G_GAN': 7.2987284660339355, 'G_L1': 58.71614074707031, 'D': 0.3012716770172119, 'F': 0.006878486834466457}\n",
      "Epoch/total_steps/alpha-beta: 0/3000/1-1 {'G_GAN': 5.918247222900391, 'G_L1': 33.839569091796875, 'D': 0.47583073377609253, 'F': 0.023110026493668556}\n",
      "Epoch/total_steps/alpha-beta: 0/3100/1-1 {'G_GAN': 7.544097900390625, 'G_L1': 96.7215805053711, 'D': 0.08623941242694855, 'F': 0.010666212067008018}\n",
      "Epoch/total_steps/alpha-beta: 0/3200/1-1 {'G_GAN': 5.972902297973633, 'G_L1': 45.39277648925781, 'D': 0.6999977231025696, 'F': 0.013009447604417801}\n",
      "Epoch/total_steps/alpha-beta: 0/3300/1-1 {'G_GAN': 7.454391002655029, 'G_L1': 42.21316146850586, 'D': 0.3786676228046417, 'F': 0.023663945496082306}\n",
      "Epoch/total_steps/alpha-beta: 0/3400/1-1 {'G_GAN': 8.168795585632324, 'G_L1': 50.32633972167969, 'D': 0.06947940587997437, 'F': 0.0052123898640275}\n",
      "Epoch/total_steps/alpha-beta: 0/3500/1-1 {'G_GAN': 7.665689468383789, 'G_L1': 47.38014221191406, 'D': 0.11292305588722229, 'F': 0.007362126372754574}\n",
      "Epoch/total_steps/alpha-beta: 0/3600/1-1 {'G_GAN': 8.304533004760742, 'G_L1': 64.66524505615234, 'D': 0.07515833526849747, 'F': 0.008023531176149845}\n",
      "Epoch/total_steps/alpha-beta: 0/3700/1-1 {'G_GAN': 8.682092666625977, 'G_L1': 39.63965606689453, 'D': 0.25657469034194946, 'F': 0.014217937365174294}\n",
      "Epoch/total_steps/alpha-beta: 0/3800/1-1 {'G_GAN': 7.638301849365234, 'G_L1': 78.36988067626953, 'D': 0.09640045464038849, 'F': 0.014670801348984241}\n",
      "Epoch/total_steps/alpha-beta: 0/3900/1-1 {'G_GAN': 6.8892364501953125, 'G_L1': 48.8631591796875, 'D': 0.5110245943069458, 'F': 0.0077681331895291805}\n",
      "Epoch/total_steps/alpha-beta: 0/4000/1-1 {'G_GAN': 7.771721363067627, 'G_L1': 56.03171157836914, 'D': 0.04583849757909775, 'F': 0.008565093390643597}\n",
      "Epoch/total_steps/alpha-beta: 0/4100/1-1 {'G_GAN': 7.996473789215088, 'G_L1': 56.72932815551758, 'D': 0.13362935185432434, 'F': 0.011361945420503616}\n",
      "Epoch/total_steps/alpha-beta: 0/4200/1-1 {'G_GAN': 7.996485233306885, 'G_L1': 42.705421447753906, 'D': 0.04230982065200806, 'F': 0.016090290620923042}\n",
      "Epoch/total_steps/alpha-beta: 0/4300/1-1 {'G_GAN': 6.5630083084106445, 'G_L1': 77.21231079101562, 'D': 0.31008175015449524, 'F': 0.007575363852083683}\n",
      "Epoch/total_steps/alpha-beta: 0/4400/1-1 {'G_GAN': 7.481277942657471, 'G_L1': 57.51869583129883, 'D': 0.22858652472496033, 'F': 0.008757248520851135}\n",
      "Epoch/total_steps/alpha-beta: 0/4500/1-1 {'G_GAN': 8.45147705078125, 'G_L1': 37.629486083984375, 'D': 0.12803904712200165, 'F': 0.009547237306833267}\n",
      "Epoch/total_steps/alpha-beta: 0/4600/1-1 {'G_GAN': 8.402596473693848, 'G_L1': 63.712711334228516, 'D': 0.12649144232273102, 'F': 0.012351367622613907}\n",
      "Epoch/total_steps/alpha-beta: 0/4700/1-1 {'G_GAN': 7.6600847244262695, 'G_L1': 49.206878662109375, 'D': 0.06945803016424179, 'F': 0.008419311605393887}\n",
      "Epoch/total_steps/alpha-beta: 0/4800/1-1 {'G_GAN': 7.621247291564941, 'G_L1': 62.317752838134766, 'D': 0.392180860042572, 'F': 0.008641136810183525}\n",
      "Epoch/total_steps/alpha-beta: 0/4900/1-1 {'G_GAN': 6.153536796569824, 'G_L1': 73.89155578613281, 'D': 1.9577667713165283, 'F': 0.004571779165416956}\n",
      "Epoch/total_steps/alpha-beta: 0/5000/1-1 {'G_GAN': 7.6374430656433105, 'G_L1': 42.614261627197266, 'D': 0.15651223063468933, 'F': 0.007243161089718342}\n",
      "Epoch/total_steps/alpha-beta: 0/5100/1-1 {'G_GAN': 6.886175632476807, 'G_L1': 56.85025405883789, 'D': 0.23289775848388672, 'F': 0.005355427041649818}\n",
      "Epoch/total_steps/alpha-beta: 0/5200/1-1 {'G_GAN': 5.798615455627441, 'G_L1': 39.678470611572266, 'D': 1.16788649559021, 'F': 0.010754863731563091}\n",
      "Epoch/total_steps/alpha-beta: 0/5300/1-1 {'G_GAN': 8.263847351074219, 'G_L1': 86.83111572265625, 'D': 0.10561434924602509, 'F': 0.006744322367012501}\n",
      "Epoch/total_steps/alpha-beta: 0/5400/1-1 {'G_GAN': 6.803694725036621, 'G_L1': 70.46418762207031, 'D': 0.3951355218887329, 'F': 0.005242636427283287}\n",
      "Epoch/total_steps/alpha-beta: 0/5500/1-1 {'G_GAN': 7.981578826904297, 'G_L1': 108.26988220214844, 'D': 0.06490228325128555, 'F': 0.013407368212938309}\n",
      "Epoch/total_steps/alpha-beta: 0/5600/1-1 {'G_GAN': 7.320289134979248, 'G_L1': 52.941715240478516, 'D': 0.1379150152206421, 'F': 0.0030706580728292465}\n",
      "Epoch/total_steps/alpha-beta: 0/5700/1-1 {'G_GAN': 7.973141193389893, 'G_L1': 59.55439376831055, 'D': 0.030175207182765007, 'F': 0.01176734920591116}\n",
      "Epoch/total_steps/alpha-beta: 0/5800/1-1 {'G_GAN': 8.284833908081055, 'G_L1': 60.21121597290039, 'D': 0.06262273341417313, 'F': 0.006977483630180359}\n",
      "Epoch/total_steps/alpha-beta: 0/5900/1-1 {'G_GAN': 8.258224487304688, 'G_L1': 35.075706481933594, 'D': 0.04807504266500473, 'F': 0.006213567219674587}\n",
      "Epoch/total_steps/alpha-beta: 0/6000/1-1 {'G_GAN': 8.383806228637695, 'G_L1': 46.3287353515625, 'D': 0.08396550267934799, 'F': 0.0107817891985178}\n",
      "Epoch/total_steps/alpha-beta: 0/6100/1-1 {'G_GAN': 8.344456672668457, 'G_L1': 59.95425033569336, 'D': 0.07266698777675629, 'F': 0.008597245439887047}\n",
      "Epoch/total_steps/alpha-beta: 0/6200/1-1 {'G_GAN': 6.1311469078063965, 'G_L1': 48.754188537597656, 'D': 0.5149170756340027, 'F': 0.004501000978052616}\n",
      "Epoch/total_steps/alpha-beta: 0/6300/1-1 {'G_GAN': 7.149686813354492, 'G_L1': 71.15396118164062, 'D': 0.2500658631324768, 'F': 0.007312756031751633}\n",
      "Epoch/total_steps/alpha-beta: 0/6400/1-1 {'G_GAN': 7.40749454498291, 'G_L1': 42.18881607055664, 'D': 0.3081147372722626, 'F': 0.004056393634527922}\n",
      "Epoch/total_steps/alpha-beta: 0/6500/1-1 {'G_GAN': 6.996418476104736, 'G_L1': 30.674816131591797, 'D': 0.25620943307876587, 'F': 0.015434334985911846}\n",
      "Epoch/total_steps/alpha-beta: 0/6600/1-1 {'G_GAN': 8.121455192565918, 'G_L1': 49.59626770019531, 'D': 0.028358401730656624, 'F': 0.006339492276310921}\n",
      "Epoch/total_steps/alpha-beta: 0/6700/1-1 {'G_GAN': 8.35389518737793, 'G_L1': 45.81657409667969, 'D': 0.12101450562477112, 'F': 0.0031661679968237877}\n",
      "Epoch/total_steps/alpha-beta: 0/6800/1-1 {'G_GAN': 7.042941093444824, 'G_L1': 40.504085540771484, 'D': 0.1503693163394928, 'F': 0.002462363336235285}\n",
      "Epoch/total_steps/alpha-beta: 0/6900/1-1 {'G_GAN': 7.426477909088135, 'G_L1': 55.55573654174805, 'D': 0.05519334226846695, 'F': 0.007539939135313034}\n",
      "Epoch/total_steps/alpha-beta: 0/7000/1-1 {'G_GAN': 7.626007080078125, 'G_L1': 70.24970245361328, 'D': 0.08646371215581894, 'F': 0.0026434799656271935}\n",
      "Epoch/total_steps/alpha-beta: 0/7100/1-1 {'G_GAN': 7.605014324188232, 'G_L1': 41.01420974731445, 'D': 0.08497186005115509, 'F': 0.00252027646638453}\n",
      "Epoch/total_steps/alpha-beta: 0/7200/1-1 {'G_GAN': 6.084473609924316, 'G_L1': 32.2652587890625, 'D': 0.4734061658382416, 'F': 0.0019388592336326838}\n",
      "Epoch/total_steps/alpha-beta: 0/7300/1-1 {'G_GAN': 7.018969535827637, 'G_L1': 85.42520904541016, 'D': 0.27489325404167175, 'F': 0.0023627576883882284}\n",
      "Epoch/total_steps/alpha-beta: 0/7400/1-1 {'G_GAN': 6.402486801147461, 'G_L1': 42.54283142089844, 'D': 0.27588963508605957, 'F': 0.004182430449873209}\n",
      "Epoch/total_steps/alpha-beta: 0/7500/1-1 {'G_GAN': 5.938089370727539, 'G_L1': 31.036848068237305, 'D': 0.7004063129425049, 'F': 0.002694114111363888}\n",
      "Epoch/total_steps/alpha-beta: 0/7600/1-1 {'G_GAN': 8.16080379486084, 'G_L1': 52.37434005737305, 'D': 0.05677836015820503, 'F': 0.0037008144427090883}\n",
      "Epoch/total_steps/alpha-beta: 0/7700/1-1 {'G_GAN': 7.534536838531494, 'G_L1': 48.51013946533203, 'D': 0.33154428005218506, 'F': 0.0018072292441502213}\n",
      "Epoch/total_steps/alpha-beta: 0/7800/1-1 {'G_GAN': 7.943121910095215, 'G_L1': 62.80522155761719, 'D': 0.0310518816113472, 'F': 0.0057301889173686504}\n",
      "Epoch/total_steps/alpha-beta: 0/7900/1-1 {'G_GAN': 8.19321060180664, 'G_L1': 34.802223205566406, 'D': 0.04974427446722984, 'F': 0.0026190797798335552}\n",
      "Epoch/total_steps/alpha-beta: 0/8000/1-1 {'G_GAN': 7.1175432205200195, 'G_L1': 38.05084991455078, 'D': 0.21175993978977203, 'F': 0.004107722546905279}\n",
      "Epoch/total_steps/alpha-beta: 0/8100/1-1 {'G_GAN': 7.780276298522949, 'G_L1': 74.96903228759766, 'D': 0.03703831136226654, 'F': 0.010518229566514492}\n",
      "Epoch/total_steps/alpha-beta: 0/8200/1-1 {'G_GAN': 7.708995819091797, 'G_L1': 33.80449295043945, 'D': 0.030776165425777435, 'F': 0.009684702381491661}\n",
      "Epoch/total_steps/alpha-beta: 0/8300/1-1 {'G_GAN': 7.522763252258301, 'G_L1': 23.80935287475586, 'D': 0.049943707883358, 'F': 0.0021161306649446487}\n",
      "Epoch/total_steps/alpha-beta: 0/8400/1-1 {'G_GAN': 7.257826805114746, 'G_L1': 29.893531799316406, 'D': 0.14615777134895325, 'F': 0.0021438393741846085}\n",
      "Epoch/total_steps/alpha-beta: 0/8500/1-1 {'G_GAN': 8.02918815612793, 'G_L1': 61.064064025878906, 'D': 0.13911926746368408, 'F': 0.004984264727681875}\n",
      "Epoch/total_steps/alpha-beta: 0/8600/1-1 {'G_GAN': 7.9883952140808105, 'G_L1': 38.462806701660156, 'D': 0.03824824094772339, 'F': 0.009075062349438667}\n",
      "Epoch/total_steps/alpha-beta: 0/8700/1-1 {'G_GAN': 6.465782165527344, 'G_L1': 81.16838073730469, 'D': 0.3243834376335144, 'F': 0.0027307465206831694}\n",
      "Epoch/total_steps/alpha-beta: 0/8800/1-1 {'G_GAN': 7.645304203033447, 'G_L1': 40.95176696777344, 'D': 0.0751340240240097, 'F': 0.00923872459679842}\n",
      "Epoch/total_steps/alpha-beta: 0/8900/1-1 {'G_GAN': 8.011362075805664, 'G_L1': 33.08267593383789, 'D': 0.03689172863960266, 'F': 0.0031728052999824286}\n",
      "Epoch/total_steps/alpha-beta: 0/9000/1-1 {'G_GAN': 7.774505615234375, 'G_L1': 50.78799819946289, 'D': 0.07414526492357254, 'F': 0.0015776701038703322}\n",
      "Epoch/total_steps/alpha-beta: 0/9100/1-1 {'G_GAN': 7.417238235473633, 'G_L1': 43.68589401245117, 'D': 0.36115360260009766, 'F': 0.002895291429013014}\n",
      "Epoch/total_steps/alpha-beta: 0/9200/1-1 {'G_GAN': 7.5521321296691895, 'G_L1': 43.371826171875, 'D': 0.11037002503871918, 'F': 0.0032599885016679764}\n",
      "Epoch/total_steps/alpha-beta: 0/9300/1-1 {'G_GAN': 7.891937255859375, 'G_L1': 63.42267990112305, 'D': 0.24139544367790222, 'F': 0.0019102185033261776}\n",
      "Epoch/total_steps/alpha-beta: 0/9400/1-1 {'G_GAN': 7.2336506843566895, 'G_L1': 56.6075553894043, 'D': 0.24763208627700806, 'F': 0.003271276131272316}\n",
      "Epoch/total_steps/alpha-beta: 0/9500/1-1 {'G_GAN': 9.585886001586914, 'G_L1': 60.436092376708984, 'D': 1.226494312286377, 'F': 0.0016162550309672952}\n",
      "Epoch/total_steps/alpha-beta: 0/9600/1-1 {'G_GAN': 6.00008487701416, 'G_L1': 38.142555236816406, 'D': 0.5073889493942261, 'F': 0.0017748342361301184}\n",
      "Epoch/total_steps/alpha-beta: 0/9700/1-1 {'G_GAN': 7.636424541473389, 'G_L1': 46.69641876220703, 'D': 0.13829797506332397, 'F': 0.0016540708020329475}\n",
      "Epoch/total_steps/alpha-beta: 0/9800/1-1 {'G_GAN': 7.472754001617432, 'G_L1': 50.239501953125, 'D': 0.06921680271625519, 'F': 0.002527147065848112}\n",
      "Epoch/total_steps/alpha-beta: 0/9900/1-1 {'G_GAN': 8.941873550415039, 'G_L1': 67.71498107910156, 'D': 0.16962285339832306, 'F': 0.0020194686949253082}\n",
      "Epoch/total_steps/alpha-beta: 0/10000/1-1 {'G_GAN': 8.186840057373047, 'G_L1': 68.31453704833984, 'D': 0.6574151515960693, 'F': 0.004415786825120449}\n",
      "Epoch/total_steps/alpha-beta: 0/10100/1-1 {'G_GAN': 6.864284515380859, 'G_L1': 66.50794219970703, 'D': 0.22174230217933655, 'F': 0.01656476967036724}\n",
      "Epoch/total_steps/alpha-beta: 0/10200/1-1 {'G_GAN': 7.495953559875488, 'G_L1': 36.597225189208984, 'D': 0.06352269649505615, 'F': 0.01595478691160679}\n",
      "Epoch/total_steps/alpha-beta: 0/10300/1-1 {'G_GAN': 8.345966339111328, 'G_L1': 77.30419158935547, 'D': 0.08971921354532242, 'F': 0.003577121999114752}\n",
      "Epoch/total_steps/alpha-beta: 0/10400/1-1 {'G_GAN': 8.669347763061523, 'G_L1': 30.070919036865234, 'D': 0.9127235412597656, 'F': 0.002194229979068041}\n",
      "Epoch/total_steps/alpha-beta: 0/10500/1-1 {'G_GAN': 8.475579261779785, 'G_L1': 80.79313659667969, 'D': 0.05295795202255249, 'F': 0.0015146638033911586}\n",
      "Epoch/total_steps/alpha-beta: 0/10600/1-1 {'G_GAN': 8.784976959228516, 'G_L1': 73.26616668701172, 'D': 0.08933505415916443, 'F': 0.0032597589306533337}\n",
      "Epoch/total_steps/alpha-beta: 0/10700/1-1 {'G_GAN': 6.787628650665283, 'G_L1': 38.454734802246094, 'D': 0.3249225616455078, 'F': 0.0034505603834986687}\n",
      "Epoch/total_steps/alpha-beta: 0/10800/1-1 {'G_GAN': 8.730010032653809, 'G_L1': 60.60959243774414, 'D': 0.30015599727630615, 'F': 0.0032948614098131657}\n",
      "Epoch/total_steps/alpha-beta: 0/10900/1-1 {'G_GAN': 7.004982948303223, 'G_L1': 32.01048278808594, 'D': 0.19470490515232086, 'F': 0.0031665561255067587}\n",
      "Epoch/total_steps/alpha-beta: 0/11000/1-1 {'G_GAN': 9.061315536499023, 'G_L1': 68.95564270019531, 'D': 0.19244731962680817, 'F': 0.0034508907701820135}\n",
      "Epoch/total_steps/alpha-beta: 0/11100/1-1 {'G_GAN': 8.578391075134277, 'G_L1': 82.3022689819336, 'D': 0.11175152659416199, 'F': 0.003092898055911064}\n",
      "Epoch/total_steps/alpha-beta: 0/11200/1-1 {'G_GAN': 8.29755973815918, 'G_L1': 59.436710357666016, 'D': 0.05363302677869797, 'F': 0.00201236829161644}\n",
      "Epoch/total_steps/alpha-beta: 0/11300/1-1 {'G_GAN': 7.944901466369629, 'G_L1': 54.53965759277344, 'D': 0.040874823927879333, 'F': 0.01685798540711403}\n",
      "Epoch/total_steps/alpha-beta: 0/11400/1-1 {'G_GAN': 6.979119777679443, 'G_L1': 53.772342681884766, 'D': 0.16557006537914276, 'F': 0.004237089306116104}\n",
      "Epoch/total_steps/alpha-beta: 0/11500/1-1 {'G_GAN': 8.27999496459961, 'G_L1': 67.8206558227539, 'D': 0.17752400040626526, 'F': 0.018265556544065475}\n",
      "Epoch/total_steps/alpha-beta: 0/11600/1-1 {'G_GAN': 8.279304504394531, 'G_L1': 65.64483642578125, 'D': 0.08764566481113434, 'F': 0.005941405892372131}\n",
      "Epoch/total_steps/alpha-beta: 0/11700/1-1 {'G_GAN': 8.147682189941406, 'G_L1': 83.97203063964844, 'D': 0.05911638215184212, 'F': 0.0014920537360012531}\n",
      "Epoch/total_steps/alpha-beta: 0/11800/1-1 {'G_GAN': 7.444559097290039, 'G_L1': 51.360069274902344, 'D': 0.08621696382761002, 'F': 0.0015211268328130245}\n",
      "Epoch/total_steps/alpha-beta: 0/11900/1-1 {'G_GAN': 6.389288425445557, 'G_L1': 64.01058197021484, 'D': 0.4870639443397522, 'F': 0.004923909902572632}\n",
      "Epoch/total_steps/alpha-beta: 0/12000/1-1 {'G_GAN': 7.441242694854736, 'G_L1': 101.56706237792969, 'D': 0.19994515180587769, 'F': 0.004831552039831877}\n",
      "保存模型 Epoch 0, iters 12000 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-512-face\n",
      "Epoch/Epochs 0/499 花费时间：210050.6013519764s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 1/12100/1-1 {'G_GAN': 6.965084552764893, 'G_L1': 32.1517333984375, 'D': 0.23298028111457825, 'F': 0.001660623587667942}\n",
      "Epoch/total_steps/alpha-beta: 1/12200/1-1 {'G_GAN': 8.568268775939941, 'G_L1': 49.834041595458984, 'D': 0.11470457911491394, 'F': 0.003575363429263234}\n",
      "Epoch/total_steps/alpha-beta: 1/12300/1-1 {'G_GAN': 6.744634628295898, 'G_L1': 71.9154052734375, 'D': 0.26927173137664795, 'F': 0.003682998474687338}\n",
      "Epoch/total_steps/alpha-beta: 1/12400/1-1 {'G_GAN': 6.9594926834106445, 'G_L1': 56.10301971435547, 'D': 0.18023376166820526, 'F': 0.0034145619720220566}\n",
      "Epoch/total_steps/alpha-beta: 1/12500/1-1 {'G_GAN': 8.631425857543945, 'G_L1': 39.09158706665039, 'D': 0.36337924003601074, 'F': 0.001938710454851389}\n",
      "Epoch/total_steps/alpha-beta: 1/12600/1-1 {'G_GAN': 6.918540000915527, 'G_L1': 33.414371490478516, 'D': 0.27908551692962646, 'F': 0.004072829149663448}\n",
      "Epoch/total_steps/alpha-beta: 1/12700/1-1 {'G_GAN': 7.9742631912231445, 'G_L1': 39.070735931396484, 'D': 0.06639857590198517, 'F': 0.001771403243765235}\n",
      "Epoch/total_steps/alpha-beta: 1/12800/1-1 {'G_GAN': 7.309837341308594, 'G_L1': 72.9410171508789, 'D': 0.10785399377346039, 'F': 0.019198037683963776}\n",
      "Epoch/total_steps/alpha-beta: 1/12900/1-1 {'G_GAN': 6.211674213409424, 'G_L1': 33.85203552246094, 'D': 0.5952372550964355, 'F': 0.003889149986207485}\n",
      "Epoch/total_steps/alpha-beta: 1/13000/1-1 {'G_GAN': 7.215796947479248, 'G_L1': 36.57707595825195, 'D': 0.14488071203231812, 'F': 0.003104927483946085}\n",
      "Epoch/total_steps/alpha-beta: 1/13100/1-1 {'G_GAN': 7.988907814025879, 'G_L1': 44.266693115234375, 'D': 0.024571159854531288, 'F': 0.001009827246889472}\n",
      "Epoch/total_steps/alpha-beta: 1/13200/1-1 {'G_GAN': 6.033517837524414, 'G_L1': 42.82467269897461, 'D': 0.7101396322250366, 'F': 0.013241153210401535}\n",
      "Epoch/total_steps/alpha-beta: 1/13300/1-1 {'G_GAN': 6.72196626663208, 'G_L1': 71.67842864990234, 'D': 0.2942380905151367, 'F': 0.002327448222786188}\n",
      "Epoch/total_steps/alpha-beta: 1/13400/1-1 {'G_GAN': 5.743076324462891, 'G_L1': 46.365989685058594, 'D': 0.5834101438522339, 'F': 0.001597607508301735}\n",
      "Epoch/total_steps/alpha-beta: 1/13500/1-1 {'G_GAN': 8.59292984008789, 'G_L1': 64.403564453125, 'D': 0.10985682904720306, 'F': 0.01624016836285591}\n",
      "Epoch/total_steps/alpha-beta: 1/13600/1-1 {'G_GAN': 6.906657695770264, 'G_L1': 64.83211517333984, 'D': 0.20042195916175842, 'F': 0.0011972549837082624}\n",
      "Epoch/total_steps/alpha-beta: 1/13700/1-1 {'G_GAN': 8.664873123168945, 'G_L1': 48.157352447509766, 'D': 0.10982154309749603, 'F': 0.0012957439757883549}\n",
      "Epoch/total_steps/alpha-beta: 1/13800/1-1 {'G_GAN': 8.40473747253418, 'G_L1': 82.69070434570312, 'D': 0.22358351945877075, 'F': 0.0013648176100105047}\n",
      "Epoch/total_steps/alpha-beta: 1/13900/1-1 {'G_GAN': 6.874181270599365, 'G_L1': 26.418155670166016, 'D': 0.28939008712768555, 'F': 0.0012917763087898493}\n",
      "Epoch/total_steps/alpha-beta: 1/14000/1-1 {'G_GAN': 5.609704494476318, 'G_L1': 42.911773681640625, 'D': 0.634445309638977, 'F': 0.0018506052438169718}\n",
      "Epoch/total_steps/alpha-beta: 1/14100/1-1 {'G_GAN': 6.2971391677856445, 'G_L1': 58.57958984375, 'D': 0.5101325511932373, 'F': 0.0013105932157486677}\n",
      "Epoch/total_steps/alpha-beta: 1/14200/1-1 {'G_GAN': 8.584198951721191, 'G_L1': 65.98389434814453, 'D': 0.19911500811576843, 'F': 0.0007704279851168394}\n",
      "Epoch/total_steps/alpha-beta: 1/14300/1-1 {'G_GAN': 6.8249359130859375, 'G_L1': 47.252079010009766, 'D': 0.16706067323684692, 'F': 0.002328396774828434}\n",
      "Epoch/total_steps/alpha-beta: 1/14400/1-1 {'G_GAN': 8.38831901550293, 'G_L1': 51.8577766418457, 'D': 0.10940229147672653, 'F': 0.0012676790356636047}\n",
      "Epoch/total_steps/alpha-beta: 1/14500/1-1 {'G_GAN': 7.214712142944336, 'G_L1': 28.135412216186523, 'D': 0.12094077467918396, 'F': 0.0015316965291276574}\n",
      "Epoch/total_steps/alpha-beta: 1/14600/1-1 {'G_GAN': 8.174083709716797, 'G_L1': 97.63543701171875, 'D': 0.06311690807342529, 'F': 0.0018654705490916967}\n",
      "Epoch/total_steps/alpha-beta: 1/14700/1-1 {'G_GAN': 8.422822952270508, 'G_L1': 47.57001495361328, 'D': 0.049740761518478394, 'F': 0.0022448422387242317}\n",
      "Epoch/total_steps/alpha-beta: 1/14800/1-1 {'G_GAN': 9.991469383239746, 'G_L1': 102.05438232421875, 'D': 0.9361597299575806, 'F': 0.004633892327547073}\n",
      "Epoch/total_steps/alpha-beta: 1/14900/1-1 {'G_GAN': 6.368223190307617, 'G_L1': 49.527645111083984, 'D': 0.3444039821624756, 'F': 0.0014356159372255206}\n",
      "Epoch/total_steps/alpha-beta: 1/15000/1-1 {'G_GAN': 7.705367088317871, 'G_L1': 28.593271255493164, 'D': 0.029679305851459503, 'F': 0.0070795160718262196}\n",
      "Epoch/total_steps/alpha-beta: 1/15100/1-1 {'G_GAN': 7.957377910614014, 'G_L1': 80.0302963256836, 'D': 0.04116593301296234, 'F': 0.0015837373211979866}\n",
      "Epoch/total_steps/alpha-beta: 1/15200/1-1 {'G_GAN': 7.570688724517822, 'G_L1': 39.492366790771484, 'D': 0.04144105315208435, 'F': 0.0016224775463342667}\n",
      "Epoch/total_steps/alpha-beta: 1/15300/1-1 {'G_GAN': 7.627815246582031, 'G_L1': 51.580726623535156, 'D': 0.04008587449789047, 'F': 0.006936891470104456}\n",
      "Epoch/total_steps/alpha-beta: 1/15400/1-1 {'G_GAN': 8.60068130493164, 'G_L1': 67.5638656616211, 'D': 0.09305613487958908, 'F': 0.0019613392651081085}\n",
      "Epoch/total_steps/alpha-beta: 1/15500/1-1 {'G_GAN': 7.0132036209106445, 'G_L1': 43.54671096801758, 'D': 0.15567710995674133, 'F': 0.0020579372067004442}\n",
      "Epoch/total_steps/alpha-beta: 1/15600/1-1 {'G_GAN': 7.285982131958008, 'G_L1': 59.41569137573242, 'D': 0.09708955138921738, 'F': 0.00134210754185915}\n",
      "Epoch/total_steps/alpha-beta: 1/15700/1-1 {'G_GAN': 5.872897148132324, 'G_L1': 57.65104293823242, 'D': 0.5190733671188354, 'F': 0.0014739809557795525}\n",
      "Epoch/total_steps/alpha-beta: 1/15800/1-1 {'G_GAN': 6.652884006500244, 'G_L1': 69.0383529663086, 'D': 0.2209867238998413, 'F': 0.000668725639116019}\n",
      "Epoch/total_steps/alpha-beta: 1/15900/1-1 {'G_GAN': 8.922956466674805, 'G_L1': 74.76789855957031, 'D': 0.14734676480293274, 'F': 0.001433783327229321}\n",
      "Epoch/total_steps/alpha-beta: 1/16000/1-1 {'G_GAN': 6.722776412963867, 'G_L1': 47.736106872558594, 'D': 0.19235579669475555, 'F': 0.004605707712471485}\n",
      "Epoch/total_steps/alpha-beta: 1/16100/1-1 {'G_GAN': 7.069607257843018, 'G_L1': 64.81068420410156, 'D': 0.13424471020698547, 'F': 0.0014468077570199966}\n",
      "Epoch/total_steps/alpha-beta: 1/16200/1-1 {'G_GAN': 5.65114164352417, 'G_L1': 46.55643081665039, 'D': 0.6477416753768921, 'F': 0.001036064699292183}\n",
      "Epoch/total_steps/alpha-beta: 1/16300/1-1 {'G_GAN': 5.594830513000488, 'G_L1': 41.98318862915039, 'D': 0.8094563484191895, 'F': 0.0020123659633100033}\n",
      "Epoch/total_steps/alpha-beta: 1/16400/1-1 {'G_GAN': 7.108182907104492, 'G_L1': 72.10615539550781, 'D': 0.1686408519744873, 'F': 0.0013924853410571814}\n",
      "Epoch/total_steps/alpha-beta: 1/16500/1-1 {'G_GAN': 6.439988613128662, 'G_L1': 36.351566314697266, 'D': 0.25065937638282776, 'F': 0.0011856399942189455}\n",
      "Epoch/total_steps/alpha-beta: 1/16600/1-1 {'G_GAN': 6.249668121337891, 'G_L1': 51.77361297607422, 'D': 1.8064351081848145, 'F': 0.0011435834458097816}\n",
      "Epoch/total_steps/alpha-beta: 1/16700/1-1 {'G_GAN': 7.325984001159668, 'G_L1': 52.518409729003906, 'D': 0.07044397294521332, 'F': 0.0017613430973142385}\n",
      "Epoch/total_steps/alpha-beta: 1/16800/1-1 {'G_GAN': 7.064994812011719, 'G_L1': 51.93901062011719, 'D': 0.10447141528129578, 'F': 0.0034984704107046127}\n",
      "Epoch/total_steps/alpha-beta: 1/16900/1-1 {'G_GAN': 8.45097541809082, 'G_L1': 60.183685302734375, 'D': 0.040800079703330994, 'F': 0.000756916357204318}\n",
      "Epoch/total_steps/alpha-beta: 1/17000/1-1 {'G_GAN': 7.472530841827393, 'G_L1': 68.05380249023438, 'D': 0.0651281476020813, 'F': 0.0009689441649243236}\n",
      "Epoch/total_steps/alpha-beta: 1/17100/1-1 {'G_GAN': 5.831203460693359, 'G_L1': 67.09069061279297, 'D': 0.8143503665924072, 'F': 0.0007786196074448526}\n",
      "Epoch/total_steps/alpha-beta: 1/17200/1-1 {'G_GAN': 7.75128173828125, 'G_L1': 33.496116638183594, 'D': 0.025084853172302246, 'F': 0.0016133107710629702}\n",
      "Epoch/total_steps/alpha-beta: 1/17300/1-1 {'G_GAN': 7.38450813293457, 'G_L1': 52.769134521484375, 'D': 0.1037171483039856, 'F': 0.001409650663845241}\n",
      "Epoch/total_steps/alpha-beta: 1/17400/1-1 {'G_GAN': 7.340816020965576, 'G_L1': 40.84172058105469, 'D': 0.11314868927001953, 'F': 0.0037464790511876345}\n",
      "Epoch/total_steps/alpha-beta: 1/17500/1-1 {'G_GAN': 8.718326568603516, 'G_L1': 81.49516296386719, 'D': 0.24362292885780334, 'F': 0.0011034500785171986}\n",
      "Epoch/total_steps/alpha-beta: 1/17600/1-1 {'G_GAN': 7.485352516174316, 'G_L1': 64.78911590576172, 'D': 0.07829080522060394, 'F': 0.0015187687240540981}\n",
      "Epoch/total_steps/alpha-beta: 1/17700/1-1 {'G_GAN': 7.694465637207031, 'G_L1': 81.69522857666016, 'D': 0.023307785391807556, 'F': 0.002601022832095623}\n",
      "Epoch/total_steps/alpha-beta: 1/17800/1-1 {'G_GAN': 7.043097496032715, 'G_L1': 46.4925651550293, 'D': 0.12455454468727112, 'F': 0.002275500912219286}\n",
      "Epoch/total_steps/alpha-beta: 1/17900/1-1 {'G_GAN': 7.806692600250244, 'G_L1': 38.93135452270508, 'D': 0.026306627318263054, 'F': 0.006160964723676443}\n",
      "Epoch/total_steps/alpha-beta: 1/18000/1-1 {'G_GAN': 7.079763889312744, 'G_L1': 31.32964324951172, 'D': 0.1718442142009735, 'F': 0.0032081922981888056}\n",
      "Epoch/total_steps/alpha-beta: 1/18100/1-1 {'G_GAN': 7.562501430511475, 'G_L1': 58.454586029052734, 'D': 0.06112927198410034, 'F': 0.0009278167854063213}\n",
      "Epoch/total_steps/alpha-beta: 1/18200/1-1 {'G_GAN': 5.266758918762207, 'G_L1': 43.96367263793945, 'D': 0.99897700548172, 'F': 0.003405321389436722}\n",
      "Epoch/total_steps/alpha-beta: 1/18300/1-1 {'G_GAN': 8.84471607208252, 'G_L1': 38.407100677490234, 'D': 0.09829668700695038, 'F': 0.0013083667727187276}\n",
      "Epoch/total_steps/alpha-beta: 1/18400/1-1 {'G_GAN': 7.709201812744141, 'G_L1': 53.043670654296875, 'D': 0.11290895938873291, 'F': 0.0016015595756471157}\n",
      "Epoch/total_steps/alpha-beta: 1/18500/1-1 {'G_GAN': 6.139512062072754, 'G_L1': 90.53040313720703, 'D': 0.38660091161727905, 'F': 0.001467687077820301}\n",
      "Epoch/total_steps/alpha-beta: 1/18600/1-1 {'G_GAN': 5.867817401885986, 'G_L1': 57.414764404296875, 'D': 0.80483478307724, 'F': 0.0009237489430233836}\n",
      "Epoch/total_steps/alpha-beta: 1/18700/1-1 {'G_GAN': 8.204290390014648, 'G_L1': 52.65342712402344, 'D': 0.024031933397054672, 'F': 0.0017552648205310106}\n",
      "Epoch/total_steps/alpha-beta: 1/18800/1-1 {'G_GAN': 7.551031112670898, 'G_L1': 29.79721450805664, 'D': 0.05261358618736267, 'F': 0.013824671506881714}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-54fd66e4be6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_gt_latent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdisplay_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mreal_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_current_visuals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\CSA.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_F\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\CSA.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSyn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnknowregion\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknownregion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMiddle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSyn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMiddle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_B\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\networks.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutermost\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# if it is the outermost, directly pass the input in.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mx_latter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mx_latter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mx_latter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\networks.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mx_latter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\CSA_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 self.h, self.w)\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         return CSAFunction.apply(input, self.mask, self.shift_sz, self.stride,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriple_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonmask_point_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_point_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_offsets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                                  self.sp_x, self.sp_y)\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\CSAFunction.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, input, mask, shift_sz, stride, triple_w, flag, nonmask_point_idx, mask_point_idx, flatten_offsets, sp_x, sp_y)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mNonparm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNonparametricShift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             _, conv_enc, conv_new_dec, _, known_patch, unknown_patch = Nonparm.buildAutoencoder(\n\u001b[0m\u001b[0;32m     43\u001b[0m                 inpatch.squeeze(), False, False, nonmask_point_idx, mask_point_idx,  shift_sz, stride)\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\util\\NonparametricShift.py\u001b[0m in \u001b[0;36mbuildAutoencoder\u001b[1;34m(self, target_img, normalize, interpolate, nonmask_point_idx, mask_point_idx, patch_size, stride)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mconv_enc_non_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_dec_non_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatches_part\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpatches_part\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mconv_enc_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_dec_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatches_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpatches_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\util\\NonparametricShift.py\u001b[0m in \u001b[0;36m_build\u001b[1;34m(self, patch_size, stride, C, target_patches, npatches, normalize, interpolate)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0menc_patches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_patches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0menc_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mconv_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练阶段\n",
    "start_epoch = 0\n",
    "total_steps = 0\n",
    "iter_start_time = time.time()\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_iter = 0\n",
    "    epoch_iter = 0\n",
    "    # 初始化数据集\n",
    "    trainset = loader.trainset() # 训练集\n",
    "    maskset = loader.maskset() # mask 数据集\n",
    "    for (image, _), mask in zip(trainset, maskset):\n",
    "        mask = mask_op(mask)\n",
    "        total_steps += model.batch_size\n",
    "        epoch_iter += model.batch_size\n",
    "        # it not only sets the input data with mask,\n",
    "        #  but also sets the latent mask.\n",
    "        model.set_input(image, mask)\n",
    "        model.set_gt_latent()\n",
    "        model.optimize_parameters()\n",
    "        if total_steps % display_freq == 0:\n",
    "            real_A, real_B, fake_B = model.get_current_visuals()\n",
    "            # real_A=input, real_B=ground truth fake_b=output\n",
    "            pic = (torch.cat([real_A, real_B, fake_B], dim=0) + 1) / 2.0\n",
    "            image_name = f\"epoch{epoch}-{total_steps}-{alpha}.png\"\n",
    "            save_image(pic, image_save_dir/image_name, ncol=1)\n",
    "        if total_steps % 100 == 0:\n",
    "            errors = model.get_current_errors()\n",
    "            t = (time.time() - iter_start_time) / model.batch_size\n",
    "            print(\n",
    "                f\"Epoch/total_steps/alpha-beta: {epoch}/{total_steps}/{alpha}-{beta}\", dict(errors))\n",
    "    if epoch % save_epoch_freq == 0:\n",
    "        print(f'保存模型 Epoch {epoch}, iters {total_steps} 在 {model.save_dir}')\n",
    "        model.save(epoch)\n",
    "    print(\n",
    "        f'Epoch/Epochs {epoch}/{epochs-1} 花费时间：{time.time() - epoch_start_time}s')\n",
    "    model.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91729c9a28b52734f57b710b306c58b64be9d1e1e07c58fcc763d6d7bdf51c2c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
