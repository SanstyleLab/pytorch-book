{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\kaggle\\pytorch-book\\apps\n"
     ]
    }
   ],
   "source": [
    "cd ../../apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import time\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "from tools.file import mkdir\n",
    "from utils.torch_loader_all import Loader\n",
    "from tools.toml import load_option\n",
    "from app import  init, mask_op, array2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root': 'E:/kaggle/datasets/buildings', 'mask': 'D:/kaggle/dataset/mask/testing_mask_dataset', 'fine_size': 256, 'batch_size': 1}\n"
     ]
    }
   ],
   "source": [
    "opt = load_option('../origin/train-256.toml')\n",
    "print(opt)\n",
    "loader = Loader(**opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "---------- Networks initialized -------------\n",
      "UnetGeneratorCSA(\n",
      "  (model): UnetSkipConnectionBlock_3(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): UnetSkipConnectionBlock_3(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "          (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (6): UnetSkipConnectionBlock_3(\n",
      "            (model): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "              (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (6): CSA(\n",
      "                (model): Sequential(\n",
      "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                  (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (5): CSA_model(threshold: 0.3125 ,triple_weight 1)\n",
      "                  (6): InnerCos(skip: True ,strength: 1)\n",
      "                  (7): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (8): UnetSkipConnectionBlock_3(\n",
      "                    (model): Sequential(\n",
      "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                      (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                      (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (6): UnetSkipConnectionBlock_3(\n",
      "                        (model): Sequential(\n",
      "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                          (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (6): UnetSkipConnectionBlock_3(\n",
      "                            (model): Sequential(\n",
      "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                              (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                              (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (6): UnetSkipConnectionBlock_3(\n",
      "                                (model): Sequential(\n",
      "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                                  (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                                  (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (6): UnetSkipConnectionBlock_3(\n",
      "                                    (model): Sequential(\n",
      "                                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), dilation=(2, 2))\n",
      "                                      (2): ReLU(inplace=True)\n",
      "                                      (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                    )\n",
      "                                  )\n",
      "                                  (7): ReLU(inplace=True)\n",
      "                                  (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                                  (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                  (10): ReLU(inplace=True)\n",
      "                                  (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                )\n",
      "                              )\n",
      "                              (7): ReLU(inplace=True)\n",
      "                              (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                              (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (10): ReLU(inplace=True)\n",
      "                              (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                            )\n",
      "                          )\n",
      "                          (7): ReLU(inplace=True)\n",
      "                          (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                          (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (10): ReLU(inplace=True)\n",
      "                          (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                        )\n",
      "                      )\n",
      "                      (7): ReLU(inplace=True)\n",
      "                      (8): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (10): ReLU(inplace=True)\n",
      "                      (11): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (9): InnerCos2(skip: True ,strength: 1)\n",
      "                  (10): ReLU(inplace=True)\n",
      "                  (11): ConvTranspose2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (12): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (13): ReLU(inplace=True)\n",
      "                  (14): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (15): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                )\n",
      "              )\n",
      "              (7): ReLU(inplace=True)\n",
      "              (8): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (9): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (10): ReLU(inplace=True)\n",
      "              (11): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (12): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (7): ReLU(inplace=True)\n",
      "          (8): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (9): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (10): ReLU(inplace=True)\n",
      "          (11): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (12): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): ConvTranspose2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 77692291\n",
      "UnetGenerator(\n",
      "  (model): UnetSkipConnectionBlock(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): UnetSkipConnectionBlock(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (3): UnetSkipConnectionBlock(\n",
      "            (model): Sequential(\n",
      "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "              (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (3): UnetSkipConnectionBlock(\n",
      "                (model): Sequential(\n",
      "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                  (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                  (3): UnetSkipConnectionBlock(\n",
      "                    (model): Sequential(\n",
      "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                      (3): UnetSkipConnectionBlock(\n",
      "                        (model): Sequential(\n",
      "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                          (3): UnetSkipConnectionBlock(\n",
      "                            (model): Sequential(\n",
      "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                              (3): UnetSkipConnectionBlock(\n",
      "                                (model): Sequential(\n",
      "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (2): ReLU(inplace=True)\n",
      "                                  (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                                  (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                                )\n",
      "                              )\n",
      "                              (4): ReLU(inplace=True)\n",
      "                              (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                              (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                            )\n",
      "                          )\n",
      "                          (4): ReLU(inplace=True)\n",
      "                          (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                          (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                        )\n",
      "                      )\n",
      "                      (4): ReLU(inplace=True)\n",
      "                      (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                      (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (4): ReLU(inplace=True)\n",
      "                  (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "                  (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "                )\n",
      "              )\n",
      "              (4): ReLU(inplace=True)\n",
      "              (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "              (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (4): ReLU(inplace=True)\n",
      "          (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "          (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (4): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 54419459\n",
      "NLayerDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 2766529\n",
      "PFDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 10487296\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CSA-256'\n",
    "beta = 1\n",
    "base_opt = load_option('../options/base.toml')\n",
    "model_opt = load_option('../options/train-new.toml')\n",
    "model = init(model_name, beta, model_opt, base_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设定\n",
    "## 固定参数\n",
    "epochs = 500\n",
    "display_freq = 49\n",
    "save_epoch_freq = 1\n",
    "\n",
    "## 模型参数\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "\n",
    "model_name = f'CSA-crop-{alpha}-{beta}'\n",
    "image_save_dir = model.save_dir / 'images'\n",
    "mkdir(image_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch/total_steps/alpha-beta: 0/100/1-1 {'G_GAN': 5.221343040466309, 'G_L1': 83.26774597167969, 'D': 0.9441598653793335, 'F': 0.09473539888858795}\n",
      "Epoch/total_steps/alpha-beta: 0/200/1-1 {'G_GAN': 6.02549409866333, 'G_L1': 88.67796325683594, 'D': 0.6372508406639099, 'F': 0.0793766900897026}\n",
      "Epoch/total_steps/alpha-beta: 0/300/1-1 {'G_GAN': 4.67491340637207, 'G_L1': 36.42228698730469, 'D': 1.3195266723632812, 'F': 0.07199794799089432}\n",
      "Epoch/total_steps/alpha-beta: 0/400/1-1 {'G_GAN': 5.666728496551514, 'G_L1': 39.03691864013672, 'D': 0.7498090267181396, 'F': 0.08707728981971741}\n",
      "Epoch/total_steps/alpha-beta: 0/500/1-1 {'G_GAN': 5.690249443054199, 'G_L1': 27.417320251464844, 'D': 0.6784244775772095, 'F': 0.045412614941596985}\n",
      "Epoch/total_steps/alpha-beta: 0/600/1-1 {'G_GAN': 5.835867404937744, 'G_L1': 31.030555725097656, 'D': 0.8857784867286682, 'F': 0.018567200750112534}\n",
      "Epoch/total_steps/alpha-beta: 0/700/1-1 {'G_GAN': 6.8938679695129395, 'G_L1': 45.42488479614258, 'D': 0.33176398277282715, 'F': 0.02051556296646595}\n",
      "Epoch/total_steps/alpha-beta: 0/800/1-1 {'G_GAN': 7.6654510498046875, 'G_L1': 34.450374603271484, 'D': 0.24411700665950775, 'F': 0.021021751686930656}\n",
      "Epoch/total_steps/alpha-beta: 0/900/1-1 {'G_GAN': 8.043259620666504, 'G_L1': 28.344371795654297, 'D': 0.24667289853096008, 'F': 0.031281478703022}\n",
      "Epoch/total_steps/alpha-beta: 0/1000/1-1 {'G_GAN': 8.244274139404297, 'G_L1': 58.94884490966797, 'D': 0.07295916229486465, 'F': 0.015268329530954361}\n",
      "Epoch/total_steps/alpha-beta: 0/1100/1-1 {'G_GAN': 7.475423812866211, 'G_L1': 64.9913101196289, 'D': 0.9109933376312256, 'F': 0.0534551739692688}\n",
      "Epoch/total_steps/alpha-beta: 0/1200/1-1 {'G_GAN': 7.870408058166504, 'G_L1': 55.5320930480957, 'D': 0.14485427737236023, 'F': 0.022697502747178078}\n",
      "Epoch/total_steps/alpha-beta: 0/1300/1-1 {'G_GAN': 6.356100082397461, 'G_L1': 28.52899169921875, 'D': 0.5241336226463318, 'F': 0.011945163831114769}\n",
      "Epoch/total_steps/alpha-beta: 0/1400/1-1 {'G_GAN': 8.270318984985352, 'G_L1': 39.172969818115234, 'D': 0.06343703716993332, 'F': 0.013185725547373295}\n",
      "Epoch/total_steps/alpha-beta: 0/1500/1-1 {'G_GAN': 7.316861152648926, 'G_L1': 70.0155029296875, 'D': 0.11426566541194916, 'F': 0.022038616240024567}\n",
      "保存模型 Epoch 0, iters 1510 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 0/499 花费时间：3534.625502347946s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 1/1600/1-1 {'G_GAN': 8.428166389465332, 'G_L1': 64.00923919677734, 'D': 0.10753804445266724, 'F': 0.020115915685892105}\n",
      "Epoch/total_steps/alpha-beta: 1/1700/1-1 {'G_GAN': 7.818538665771484, 'G_L1': 26.48402976989746, 'D': 0.1380319744348526, 'F': 0.010761091485619545}\n",
      "Epoch/total_steps/alpha-beta: 1/1800/1-1 {'G_GAN': 7.536784648895264, 'G_L1': 30.91518211364746, 'D': 0.07562602311372757, 'F': 0.011779479682445526}\n",
      "Epoch/total_steps/alpha-beta: 1/1900/1-1 {'G_GAN': 7.988578796386719, 'G_L1': 46.62509536743164, 'D': 0.10079941153526306, 'F': 0.011966878548264503}\n",
      "Epoch/total_steps/alpha-beta: 1/2000/1-1 {'G_GAN': 6.264012813568115, 'G_L1': 30.52324104309082, 'D': 0.5651882290840149, 'F': 0.007982879877090454}\n",
      "Epoch/total_steps/alpha-beta: 1/2100/1-1 {'G_GAN': 6.512102127075195, 'G_L1': 37.93498992919922, 'D': 0.37565556168556213, 'F': 0.009405240416526794}\n",
      "Epoch/total_steps/alpha-beta: 1/2200/1-1 {'G_GAN': 8.427682876586914, 'G_L1': 32.051002502441406, 'D': 0.1625453382730484, 'F': 0.010284006595611572}\n",
      "Epoch/total_steps/alpha-beta: 1/2300/1-1 {'G_GAN': 8.593223571777344, 'G_L1': 33.66913604736328, 'D': 0.14964205026626587, 'F': 0.007105847354978323}\n",
      "Epoch/total_steps/alpha-beta: 1/2400/1-1 {'G_GAN': 8.189874649047852, 'G_L1': 33.00751876831055, 'D': 0.07679690420627594, 'F': 0.010635076090693474}\n",
      "Epoch/total_steps/alpha-beta: 1/2500/1-1 {'G_GAN': 7.370434761047363, 'G_L1': 29.66301155090332, 'D': 0.19138029217720032, 'F': 0.008423855528235435}\n",
      "Epoch/total_steps/alpha-beta: 1/2600/1-1 {'G_GAN': 8.103010177612305, 'G_L1': 36.30322265625, 'D': 0.1136893630027771, 'F': 0.007825993932783604}\n",
      "Epoch/total_steps/alpha-beta: 1/2700/1-1 {'G_GAN': 7.271125793457031, 'G_L1': 46.809757232666016, 'D': 0.15606406331062317, 'F': 0.012355662882328033}\n",
      "Epoch/total_steps/alpha-beta: 1/2800/1-1 {'G_GAN': 7.263396263122559, 'G_L1': 63.121498107910156, 'D': 0.215505450963974, 'F': 0.009749582037329674}\n",
      "Epoch/total_steps/alpha-beta: 1/2900/1-1 {'G_GAN': 7.939448356628418, 'G_L1': 44.44766616821289, 'D': 0.08629480004310608, 'F': 0.006927476730197668}\n",
      "Epoch/total_steps/alpha-beta: 1/3000/1-1 {'G_GAN': 8.316481590270996, 'G_L1': 33.41863250732422, 'D': 0.0997159332036972, 'F': 0.004561701323837042}\n",
      "保存模型 Epoch 1, iters 3020 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 1/499 花费时间：5446.630384683609s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 2/3100/1-1 {'G_GAN': 8.299691200256348, 'G_L1': 28.7686710357666, 'D': 0.04245103895664215, 'F': 0.004737226292490959}\n",
      "Epoch/total_steps/alpha-beta: 2/3200/1-1 {'G_GAN': 7.823990821838379, 'G_L1': 43.53765106201172, 'D': 0.08205348998308182, 'F': 0.009919518604874611}\n",
      "Epoch/total_steps/alpha-beta: 2/3300/1-1 {'G_GAN': 8.66282844543457, 'G_L1': 27.7099609375, 'D': 0.13705968856811523, 'F': 0.015051471069455147}\n",
      "Epoch/total_steps/alpha-beta: 2/3400/1-1 {'G_GAN': 7.666674613952637, 'G_L1': 46.43721389770508, 'D': 0.05737607181072235, 'F': 0.013067970052361488}\n",
      "Epoch/total_steps/alpha-beta: 2/3500/1-1 {'G_GAN': 6.780804634094238, 'G_L1': 68.08843994140625, 'D': 0.38170725107192993, 'F': 0.019334472715854645}\n",
      "Epoch/total_steps/alpha-beta: 2/3600/1-1 {'G_GAN': 7.848910331726074, 'G_L1': 25.976961135864258, 'D': 0.043474599719047546, 'F': 0.011373501271009445}\n",
      "Epoch/total_steps/alpha-beta: 2/3700/1-1 {'G_GAN': 5.818130970001221, 'G_L1': 26.702903747558594, 'D': 0.6249629855155945, 'F': 0.041573621332645416}\n",
      "Epoch/total_steps/alpha-beta: 2/3800/1-1 {'G_GAN': 8.388033866882324, 'G_L1': 29.35028648376465, 'D': 0.060524988919496536, 'F': 0.007243450731039047}\n",
      "Epoch/total_steps/alpha-beta: 2/3900/1-1 {'G_GAN': 7.244366645812988, 'G_L1': 39.51932144165039, 'D': 0.11009237915277481, 'F': 0.005274617113173008}\n",
      "Epoch/total_steps/alpha-beta: 2/4000/1-1 {'G_GAN': 6.482147216796875, 'G_L1': 29.623138427734375, 'D': 0.2992338538169861, 'F': 0.014674166217446327}\n",
      "Epoch/total_steps/alpha-beta: 2/4100/1-1 {'G_GAN': 8.158270835876465, 'G_L1': 40.543521881103516, 'D': 0.04596415162086487, 'F': 0.012680762447416782}\n",
      "Epoch/total_steps/alpha-beta: 2/4200/1-1 {'G_GAN': 7.52288818359375, 'G_L1': 32.21968078613281, 'D': 0.09348257631063461, 'F': 0.010263110511004925}\n",
      "Epoch/total_steps/alpha-beta: 2/4300/1-1 {'G_GAN': 6.868775844573975, 'G_L1': 20.360374450683594, 'D': 0.25589117407798767, 'F': 0.009662169963121414}\n",
      "Epoch/total_steps/alpha-beta: 2/4400/1-1 {'G_GAN': 6.815614700317383, 'G_L1': 20.120643615722656, 'D': 0.18305104970932007, 'F': 0.012116104364395142}\n",
      "Epoch/total_steps/alpha-beta: 2/4500/1-1 {'G_GAN': 7.946298599243164, 'G_L1': 62.33978271484375, 'D': 0.24830372631549835, 'F': 0.006963749416172504}\n",
      "保存模型 Epoch 2, iters 4530 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 2/499 花费时间：7209.666450738907s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 3/4600/1-1 {'G_GAN': 8.565166473388672, 'G_L1': 27.058393478393555, 'D': 0.08892261981964111, 'F': 0.005170776508748531}\n",
      "Epoch/total_steps/alpha-beta: 3/4700/1-1 {'G_GAN': 7.297205924987793, 'G_L1': 28.403705596923828, 'D': 0.13894546031951904, 'F': 0.00994197092950344}\n",
      "Epoch/total_steps/alpha-beta: 3/4800/1-1 {'G_GAN': 7.884485721588135, 'G_L1': 48.436607360839844, 'D': 0.03568413853645325, 'F': 0.006153199356049299}\n",
      "Epoch/total_steps/alpha-beta: 3/4900/1-1 {'G_GAN': 8.00999927520752, 'G_L1': 23.159881591796875, 'D': 0.03934673219919205, 'F': 0.006490173749625683}\n",
      "Epoch/total_steps/alpha-beta: 3/5000/1-1 {'G_GAN': 7.727204322814941, 'G_L1': 47.38936996459961, 'D': 0.09008850157260895, 'F': 0.0064593893475830555}\n",
      "Epoch/total_steps/alpha-beta: 3/5100/1-1 {'G_GAN': 6.849704742431641, 'G_L1': 27.8806095123291, 'D': 0.1583128571510315, 'F': 0.01854669488966465}\n",
      "Epoch/total_steps/alpha-beta: 3/5200/1-1 {'G_GAN': 8.161042213439941, 'G_L1': 23.691923141479492, 'D': 0.04428713023662567, 'F': 0.02426164411008358}\n",
      "Epoch/total_steps/alpha-beta: 3/5300/1-1 {'G_GAN': 7.351716995239258, 'G_L1': 46.74689865112305, 'D': 0.1647501289844513, 'F': 0.011301878839731216}\n",
      "Epoch/total_steps/alpha-beta: 3/5400/1-1 {'G_GAN': 8.07183837890625, 'G_L1': 30.018646240234375, 'D': 0.05703483521938324, 'F': 0.004858609288930893}\n",
      "Epoch/total_steps/alpha-beta: 3/5500/1-1 {'G_GAN': 7.646499156951904, 'G_L1': 22.73050308227539, 'D': 0.12465661764144897, 'F': 0.005663757678121328}\n",
      "Epoch/total_steps/alpha-beta: 3/5600/1-1 {'G_GAN': 7.807973861694336, 'G_L1': 35.29584503173828, 'D': 0.03137323632836342, 'F': 0.00973778497427702}\n",
      "Epoch/total_steps/alpha-beta: 3/5700/1-1 {'G_GAN': 8.429466247558594, 'G_L1': 56.23924255371094, 'D': 0.45957648754119873, 'F': 0.01484852097928524}\n",
      "Epoch/total_steps/alpha-beta: 3/5800/1-1 {'G_GAN': 7.97641658782959, 'G_L1': 42.733394622802734, 'D': 0.06819362938404083, 'F': 0.009337061084806919}\n",
      "Epoch/total_steps/alpha-beta: 3/5900/1-1 {'G_GAN': 8.390377044677734, 'G_L1': 31.32245635986328, 'D': 0.0972868949174881, 'F': 0.012103542685508728}\n",
      "Epoch/total_steps/alpha-beta: 3/6000/1-1 {'G_GAN': 8.447383880615234, 'G_L1': 27.842920303344727, 'D': 0.11219148337841034, 'F': 0.004981164820492268}\n",
      "保存模型 Epoch 3, iters 6040 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 3/499 花费时间：7528.545564413071s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 4/6100/1-1 {'G_GAN': 8.566417694091797, 'G_L1': 45.29093551635742, 'D': 0.0941094160079956, 'F': 0.008840909227728844}\n",
      "Epoch/total_steps/alpha-beta: 4/6200/1-1 {'G_GAN': 7.6873087882995605, 'G_L1': 20.321151733398438, 'D': 0.06237989291548729, 'F': 0.018412264063954353}\n",
      "Epoch/total_steps/alpha-beta: 4/6300/1-1 {'G_GAN': 7.405055046081543, 'G_L1': 37.15827178955078, 'D': 0.0660867691040039, 'F': 0.011548178270459175}\n",
      "Epoch/total_steps/alpha-beta: 4/6400/1-1 {'G_GAN': 6.960352897644043, 'G_L1': 40.310272216796875, 'D': 0.18959826231002808, 'F': 0.022615835070610046}\n",
      "Epoch/total_steps/alpha-beta: 4/6500/1-1 {'G_GAN': 8.573577880859375, 'G_L1': 44.57759094238281, 'D': 0.0696132481098175, 'F': 0.02339193969964981}\n",
      "Epoch/total_steps/alpha-beta: 4/6600/1-1 {'G_GAN': 6.568777084350586, 'G_L1': 24.576114654541016, 'D': 0.2346973866224289, 'F': 0.013700888492166996}\n",
      "Epoch/total_steps/alpha-beta: 4/6700/1-1 {'G_GAN': 7.094670295715332, 'G_L1': 40.851253509521484, 'D': 0.1264205276966095, 'F': 0.013660675846040249}\n",
      "Epoch/total_steps/alpha-beta: 4/6800/1-1 {'G_GAN': 6.803456783294678, 'G_L1': 27.008426666259766, 'D': 0.17449578642845154, 'F': 0.006756983231753111}\n",
      "Epoch/total_steps/alpha-beta: 4/6900/1-1 {'G_GAN': 7.921754837036133, 'G_L1': 34.20774459838867, 'D': 0.09775635600090027, 'F': 0.010304803028702736}\n",
      "Epoch/total_steps/alpha-beta: 4/7000/1-1 {'G_GAN': 7.02370023727417, 'G_L1': 32.70384979248047, 'D': 0.16883787512779236, 'F': 0.006673095282167196}\n",
      "Epoch/total_steps/alpha-beta: 4/7100/1-1 {'G_GAN': 6.841863632202148, 'G_L1': 30.871217727661133, 'D': 0.24002349376678467, 'F': 0.00897135678678751}\n",
      "Epoch/total_steps/alpha-beta: 4/7200/1-1 {'G_GAN': 8.16363525390625, 'G_L1': 64.0650634765625, 'D': 0.025036532431840897, 'F': 0.01065028179436922}\n",
      "Epoch/total_steps/alpha-beta: 4/7300/1-1 {'G_GAN': 7.502173900604248, 'G_L1': 20.20645523071289, 'D': 0.10947255790233612, 'F': 0.006755325943231583}\n",
      "Epoch/total_steps/alpha-beta: 4/7400/1-1 {'G_GAN': 8.01827621459961, 'G_L1': 65.2905502319336, 'D': 0.03082120046019554, 'F': 0.007592176087200642}\n",
      "Epoch/total_steps/alpha-beta: 4/7500/1-1 {'G_GAN': 6.88211727142334, 'G_L1': 30.366382598876953, 'D': 0.2959393262863159, 'F': 0.005728885065764189}\n",
      "保存模型 Epoch 4, iters 7550 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 4/499 花费时间：7526.910454750061s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 5/7600/1-1 {'G_GAN': 8.678319931030273, 'G_L1': 43.121280670166016, 'D': 0.12183922529220581, 'F': 0.004068032838404179}\n",
      "Epoch/total_steps/alpha-beta: 5/7700/1-1 {'G_GAN': 7.031343460083008, 'G_L1': 19.14370346069336, 'D': 0.16885197162628174, 'F': 0.006844268646091223}\n",
      "Epoch/total_steps/alpha-beta: 5/7800/1-1 {'G_GAN': 7.658452987670898, 'G_L1': 31.821609497070312, 'D': 0.08585581183433533, 'F': 0.004138667602092028}\n",
      "Epoch/total_steps/alpha-beta: 5/7900/1-1 {'G_GAN': 8.024579048156738, 'G_L1': 23.567441940307617, 'D': 0.032432034611701965, 'F': 0.003352242987602949}\n",
      "Epoch/total_steps/alpha-beta: 5/8000/1-1 {'G_GAN': 7.145682334899902, 'G_L1': 64.53060150146484, 'D': 0.10972775518894196, 'F': 0.004059918690472841}\n",
      "Epoch/total_steps/alpha-beta: 5/8100/1-1 {'G_GAN': 7.538158416748047, 'G_L1': 41.6198616027832, 'D': 0.08403092622756958, 'F': 0.009180136024951935}\n",
      "Epoch/total_steps/alpha-beta: 5/8200/1-1 {'G_GAN': 6.8745527267456055, 'G_L1': 31.91886329650879, 'D': 0.2023436427116394, 'F': 0.00541455764323473}\n",
      "Epoch/total_steps/alpha-beta: 5/8300/1-1 {'G_GAN': 8.066884994506836, 'G_L1': 33.72520065307617, 'D': 0.05716874450445175, 'F': 0.024386577308177948}\n",
      "Epoch/total_steps/alpha-beta: 5/8400/1-1 {'G_GAN': 6.480495452880859, 'G_L1': 32.784385681152344, 'D': 0.5478055477142334, 'F': 0.004083499312400818}\n",
      "Epoch/total_steps/alpha-beta: 5/8500/1-1 {'G_GAN': 7.754925727844238, 'G_L1': 42.15970993041992, 'D': 0.028500564396381378, 'F': 0.0034901758190244436}\n",
      "Epoch/total_steps/alpha-beta: 5/8600/1-1 {'G_GAN': 6.155020713806152, 'G_L1': 30.938831329345703, 'D': 0.6596901416778564, 'F': 0.01026422530412674}\n",
      "Epoch/total_steps/alpha-beta: 5/8700/1-1 {'G_GAN': 8.023233413696289, 'G_L1': 50.472225189208984, 'D': 0.030791763216257095, 'F': 0.011800339445471764}\n",
      "Epoch/total_steps/alpha-beta: 5/8800/1-1 {'G_GAN': 7.095969200134277, 'G_L1': 65.7837142944336, 'D': 0.12785720825195312, 'F': 0.005544520448893309}\n",
      "Epoch/total_steps/alpha-beta: 5/8900/1-1 {'G_GAN': 7.541990280151367, 'G_L1': 51.231842041015625, 'D': 0.09195239841938019, 'F': 0.006881514564156532}\n",
      "Epoch/total_steps/alpha-beta: 5/9000/1-1 {'G_GAN': 7.963187217712402, 'G_L1': 35.39965057373047, 'D': 0.038617558777332306, 'F': 0.004773148335516453}\n",
      "保存模型 Epoch 5, iters 9060 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 5/499 花费时间：7529.390153646469s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 6/9100/1-1 {'G_GAN': 7.732253074645996, 'G_L1': 43.7108268737793, 'D': 0.04830791428685188, 'F': 0.011754848062992096}\n",
      "Epoch/total_steps/alpha-beta: 6/9200/1-1 {'G_GAN': 7.649668216705322, 'G_L1': 25.209569931030273, 'D': 0.06097712367773056, 'F': 0.007976915687322617}\n",
      "Epoch/total_steps/alpha-beta: 6/9300/1-1 {'G_GAN': 7.233345985412598, 'G_L1': 26.073062896728516, 'D': 0.10236751288175583, 'F': 0.007357308641076088}\n",
      "Epoch/total_steps/alpha-beta: 6/9400/1-1 {'G_GAN': 5.937966823577881, 'G_L1': 23.520549774169922, 'D': 0.5277791023254395, 'F': 0.004812457598745823}\n",
      "Epoch/total_steps/alpha-beta: 6/9500/1-1 {'G_GAN': 8.15849494934082, 'G_L1': 31.517017364501953, 'D': 0.02653360180556774, 'F': 0.0025087168905884027}\n",
      "Epoch/total_steps/alpha-beta: 6/9600/1-1 {'G_GAN': 7.462815761566162, 'G_L1': 50.260154724121094, 'D': 0.11497488617897034, 'F': 0.006912964396178722}\n",
      "Epoch/total_steps/alpha-beta: 6/9700/1-1 {'G_GAN': 7.60418701171875, 'G_L1': 21.591787338256836, 'D': 0.07773880660533905, 'F': 0.008419658988714218}\n",
      "Epoch/total_steps/alpha-beta: 6/9800/1-1 {'G_GAN': 7.258673191070557, 'G_L1': 21.102819442749023, 'D': 0.07398585975170135, 'F': 0.012293145060539246}\n",
      "Epoch/total_steps/alpha-beta: 6/9900/1-1 {'G_GAN': 7.0645599365234375, 'G_L1': 20.439132690429688, 'D': 0.12476161867380142, 'F': 0.004790159873664379}\n",
      "Epoch/total_steps/alpha-beta: 6/10000/1-1 {'G_GAN': 6.818017959594727, 'G_L1': 38.52790069580078, 'D': 0.1876761019229889, 'F': 0.005086769349873066}\n",
      "Epoch/total_steps/alpha-beta: 6/10100/1-1 {'G_GAN': 8.039544105529785, 'G_L1': 36.776611328125, 'D': 0.021089140325784683, 'F': 0.005143746733665466}\n",
      "Epoch/total_steps/alpha-beta: 6/10200/1-1 {'G_GAN': 7.527528762817383, 'G_L1': 55.46781921386719, 'D': 0.09542284160852432, 'F': 0.004555689170956612}\n",
      "Epoch/total_steps/alpha-beta: 6/10300/1-1 {'G_GAN': 7.450767517089844, 'G_L1': 33.21209716796875, 'D': 0.04556446522474289, 'F': 0.0031931549310684204}\n",
      "Epoch/total_steps/alpha-beta: 6/10400/1-1 {'G_GAN': 8.198694229125977, 'G_L1': 33.35210418701172, 'D': 0.01950738951563835, 'F': 0.0034179033245891333}\n",
      "Epoch/total_steps/alpha-beta: 6/10500/1-1 {'G_GAN': 7.967572212219238, 'G_L1': 33.59809112548828, 'D': 0.05338810011744499, 'F': 0.005474750883877277}\n",
      "保存模型 Epoch 6, iters 10570 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 6/499 花费时间：7495.528801679611s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 7/10600/1-1 {'G_GAN': 7.6248779296875, 'G_L1': 29.228878021240234, 'D': 0.06279444694519043, 'F': 0.003956685774028301}\n",
      "Epoch/total_steps/alpha-beta: 7/10700/1-1 {'G_GAN': 8.623394012451172, 'G_L1': 48.77614212036133, 'D': 0.1212463453412056, 'F': 0.0038354680873453617}\n",
      "Epoch/total_steps/alpha-beta: 7/10800/1-1 {'G_GAN': 8.535538673400879, 'G_L1': 23.573339462280273, 'D': 0.26092103123664856, 'F': 0.02034822106361389}\n",
      "Epoch/total_steps/alpha-beta: 7/10900/1-1 {'G_GAN': 7.304739952087402, 'G_L1': 52.720272064208984, 'D': 0.17319446802139282, 'F': 0.004917722661048174}\n",
      "Epoch/total_steps/alpha-beta: 7/11000/1-1 {'G_GAN': 8.496955871582031, 'G_L1': 32.15869140625, 'D': 0.19627061486244202, 'F': 0.0034651909954845905}\n",
      "Epoch/total_steps/alpha-beta: 7/11100/1-1 {'G_GAN': 7.4414286613464355, 'G_L1': 22.528148651123047, 'D': 0.12145271897315979, 'F': 0.0053456611931324005}\n",
      "Epoch/total_steps/alpha-beta: 7/11200/1-1 {'G_GAN': 8.624886512756348, 'G_L1': 26.956111907958984, 'D': 0.12476585060358047, 'F': 0.006073706317692995}\n",
      "Epoch/total_steps/alpha-beta: 7/11300/1-1 {'G_GAN': 6.48762845993042, 'G_L1': 41.00849914550781, 'D': 0.2993772625923157, 'F': 0.005646781995892525}\n",
      "Epoch/total_steps/alpha-beta: 7/11400/1-1 {'G_GAN': 8.186914443969727, 'G_L1': 49.16712188720703, 'D': 0.05381361395120621, 'F': 0.008214539848268032}\n",
      "Epoch/total_steps/alpha-beta: 7/11500/1-1 {'G_GAN': 7.721314430236816, 'G_L1': 42.0952033996582, 'D': 0.08224791288375854, 'F': 0.003950752317905426}\n",
      "Epoch/total_steps/alpha-beta: 7/11600/1-1 {'G_GAN': 7.064647674560547, 'G_L1': 31.448291778564453, 'D': 0.15998078882694244, 'F': 0.01009608618915081}\n",
      "Epoch/total_steps/alpha-beta: 7/11700/1-1 {'G_GAN': 7.954371929168701, 'G_L1': 42.78851318359375, 'D': 0.025792140513658524, 'F': 0.006111938506364822}\n",
      "Epoch/total_steps/alpha-beta: 7/11800/1-1 {'G_GAN': 7.923455238342285, 'G_L1': 30.544158935546875, 'D': 0.05312065780162811, 'F': 0.012242168188095093}\n",
      "Epoch/total_steps/alpha-beta: 7/11900/1-1 {'G_GAN': 7.227481842041016, 'G_L1': 36.183536529541016, 'D': 0.12282086908817291, 'F': 0.005290444009006023}\n",
      "Epoch/total_steps/alpha-beta: 7/12000/1-1 {'G_GAN': 7.887233734130859, 'G_L1': 24.613788604736328, 'D': 0.11584547162055969, 'F': 0.0029767751693725586}\n",
      "保存模型 Epoch 7, iters 12080 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 7/499 花费时间：7413.103918552399s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 8/12100/1-1 {'G_GAN': 7.581682205200195, 'G_L1': 34.474464416503906, 'D': 0.05790848284959793, 'F': 0.0035234112292528152}\n",
      "Epoch/total_steps/alpha-beta: 8/12200/1-1 {'G_GAN': 7.024021148681641, 'G_L1': 41.65107727050781, 'D': 0.15041401982307434, 'F': 0.004791233688592911}\n",
      "Epoch/total_steps/alpha-beta: 8/12300/1-1 {'G_GAN': 7.7638258934021, 'G_L1': 38.13228225708008, 'D': 0.01719258539378643, 'F': 0.005442150868475437}\n",
      "Epoch/total_steps/alpha-beta: 8/12400/1-1 {'G_GAN': 7.288402557373047, 'G_L1': 58.10588455200195, 'D': 0.10702061653137207, 'F': 0.0029621128924191}\n",
      "Epoch/total_steps/alpha-beta: 8/12500/1-1 {'G_GAN': 7.613567352294922, 'G_L1': 41.18113708496094, 'D': 0.12718082964420319, 'F': 0.003136741928756237}\n",
      "Epoch/total_steps/alpha-beta: 8/12600/1-1 {'G_GAN': 7.533107280731201, 'G_L1': 45.24429702758789, 'D': 0.06324156373739243, 'F': 0.00745246559381485}\n",
      "Epoch/total_steps/alpha-beta: 8/12700/1-1 {'G_GAN': 7.9813103675842285, 'G_L1': 23.749958038330078, 'D': 0.020820695906877518, 'F': 0.009065713733434677}\n",
      "Epoch/total_steps/alpha-beta: 8/12800/1-1 {'G_GAN': 7.772655487060547, 'G_L1': 67.95085906982422, 'D': 0.0983620211482048, 'F': 0.004236478824168444}\n",
      "Epoch/total_steps/alpha-beta: 8/12900/1-1 {'G_GAN': 7.928244590759277, 'G_L1': 19.054906845092773, 'D': 0.06631708145141602, 'F': 0.0064378827810287476}\n",
      "Epoch/total_steps/alpha-beta: 8/13000/1-1 {'G_GAN': 8.357902526855469, 'G_L1': 36.96731185913086, 'D': 0.037195317447185516, 'F': 0.005653058178722858}\n",
      "Epoch/total_steps/alpha-beta: 8/13100/1-1 {'G_GAN': 6.973226070404053, 'G_L1': 26.47764015197754, 'D': 0.17010092735290527, 'F': 0.00506189651787281}\n",
      "Epoch/total_steps/alpha-beta: 8/13200/1-1 {'G_GAN': 5.7928314208984375, 'G_L1': 15.053328514099121, 'D': 0.625880777835846, 'F': 0.004256725776940584}\n",
      "Epoch/total_steps/alpha-beta: 8/13300/1-1 {'G_GAN': 8.065481185913086, 'G_L1': 71.77478790283203, 'D': 0.23177891969680786, 'F': 0.0064806207083165646}\n",
      "Epoch/total_steps/alpha-beta: 8/13400/1-1 {'G_GAN': 7.936908721923828, 'G_L1': 30.626007080078125, 'D': 0.02110428735613823, 'F': 0.0026462457608431578}\n",
      "Epoch/total_steps/alpha-beta: 8/13500/1-1 {'G_GAN': 8.294858932495117, 'G_L1': 40.485496520996094, 'D': 0.10770836472511292, 'F': 0.004948494955897331}\n",
      "保存模型 Epoch 8, iters 13590 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 8/499 花费时间：6497.949520349503s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 9/13600/1-1 {'G_GAN': 7.967746257781982, 'G_L1': 29.19915008544922, 'D': 0.02591315470635891, 'F': 0.004626010544598103}\n",
      "Epoch/total_steps/alpha-beta: 9/13700/1-1 {'G_GAN': 7.723950386047363, 'G_L1': 18.31588363647461, 'D': 0.026470214128494263, 'F': 0.004633272998034954}\n",
      "Epoch/total_steps/alpha-beta: 9/13800/1-1 {'G_GAN': 8.364426612854004, 'G_L1': 38.08037185668945, 'D': 0.05775924772024155, 'F': 0.00221813190728426}\n",
      "Epoch/total_steps/alpha-beta: 9/13900/1-1 {'G_GAN': 6.015634536743164, 'G_L1': 21.672826766967773, 'D': 0.6788519620895386, 'F': 0.0037434487603604794}\n",
      "Epoch/total_steps/alpha-beta: 9/14000/1-1 {'G_GAN': 5.877560138702393, 'G_L1': 21.45376968383789, 'D': 0.6974241733551025, 'F': 0.0118287093937397}\n",
      "Epoch/total_steps/alpha-beta: 9/14100/1-1 {'G_GAN': 6.6283440589904785, 'G_L1': 20.299779891967773, 'D': 0.7582746744155884, 'F': 0.04505133628845215}\n",
      "Epoch/total_steps/alpha-beta: 9/14200/1-1 {'G_GAN': 6.308126449584961, 'G_L1': 49.737205505371094, 'D': 0.4797475337982178, 'F': 0.010836103931069374}\n",
      "Epoch/total_steps/alpha-beta: 9/14300/1-1 {'G_GAN': 7.847025394439697, 'G_L1': 41.917701721191406, 'D': 0.032135751098394394, 'F': 0.0046108197420835495}\n",
      "Epoch/total_steps/alpha-beta: 9/14400/1-1 {'G_GAN': 8.002569198608398, 'G_L1': 71.05892181396484, 'D': 0.10304535925388336, 'F': 0.0036131732631474733}\n",
      "Epoch/total_steps/alpha-beta: 9/14500/1-1 {'G_GAN': 7.617059707641602, 'G_L1': 27.433788299560547, 'D': 0.06742973625659943, 'F': 0.006724053993821144}\n",
      "Epoch/total_steps/alpha-beta: 9/14600/1-1 {'G_GAN': 7.740251541137695, 'G_L1': 22.695158004760742, 'D': 0.06543239951133728, 'F': 0.008162463083863258}\n",
      "Epoch/total_steps/alpha-beta: 9/14700/1-1 {'G_GAN': 7.137923240661621, 'G_L1': 46.50149917602539, 'D': 0.13832157850265503, 'F': 0.003222073893994093}\n",
      "Epoch/total_steps/alpha-beta: 9/14800/1-1 {'G_GAN': 8.158252716064453, 'G_L1': 19.84181022644043, 'D': 0.05569646134972572, 'F': 0.005258960649371147}\n",
      "Epoch/total_steps/alpha-beta: 9/14900/1-1 {'G_GAN': 5.5509443283081055, 'G_L1': 20.219554901123047, 'D': 0.8138083815574646, 'F': 0.00522975530475378}\n",
      "Epoch/total_steps/alpha-beta: 9/15000/1-1 {'G_GAN': 6.772518157958984, 'G_L1': 21.713930130004883, 'D': 0.22800469398498535, 'F': 0.008440765552222729}\n",
      "Epoch/total_steps/alpha-beta: 9/15100/1-1 {'G_GAN': 7.7085113525390625, 'G_L1': 49.46350860595703, 'D': 0.026264747604727745, 'F': 0.005190309137105942}\n",
      "保存模型 Epoch 9, iters 15100 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 9/499 花费时间：6301.597240447998s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 10/15200/1-1 {'G_GAN': 8.44527816772461, 'G_L1': 38.36606216430664, 'D': 0.0737876296043396, 'F': 0.003391744801774621}\n",
      "Epoch/total_steps/alpha-beta: 10/15300/1-1 {'G_GAN': 7.854788303375244, 'G_L1': 36.78287887573242, 'D': 0.02683226391673088, 'F': 0.0076011549681425095}\n",
      "Epoch/total_steps/alpha-beta: 10/15400/1-1 {'G_GAN': 7.852246284484863, 'G_L1': 43.75490951538086, 'D': 0.022484688088297844, 'F': 0.0051782140508294106}\n",
      "Epoch/total_steps/alpha-beta: 10/15500/1-1 {'G_GAN': 6.319469451904297, 'G_L1': 15.495850563049316, 'D': 0.41958701610565186, 'F': 0.006682357285171747}\n",
      "Epoch/total_steps/alpha-beta: 10/15600/1-1 {'G_GAN': 8.627874374389648, 'G_L1': 33.9821891784668, 'D': 0.10430874675512314, 'F': 0.005523717496544123}\n",
      "Epoch/total_steps/alpha-beta: 10/15700/1-1 {'G_GAN': 8.77853775024414, 'G_L1': 28.33699607849121, 'D': 0.14931735396385193, 'F': 0.004621438682079315}\n",
      "Epoch/total_steps/alpha-beta: 10/15800/1-1 {'G_GAN': 8.67558479309082, 'G_L1': 17.034799575805664, 'D': 0.06679384410381317, 'F': 0.0033715341705828905}\n",
      "Epoch/total_steps/alpha-beta: 10/15900/1-1 {'G_GAN': 7.480027198791504, 'G_L1': 29.66385269165039, 'D': 0.04866645485162735, 'F': 0.005316977854818106}\n",
      "Epoch/total_steps/alpha-beta: 10/16000/1-1 {'G_GAN': 8.516335487365723, 'G_L1': 45.27458953857422, 'D': 0.05196388438344002, 'F': 0.002884333487600088}\n",
      "Epoch/total_steps/alpha-beta: 10/16100/1-1 {'G_GAN': 6.917342185974121, 'G_L1': 36.28127670288086, 'D': 0.17571738362312317, 'F': 0.00514273252338171}\n",
      "Epoch/total_steps/alpha-beta: 10/16200/1-1 {'G_GAN': 8.234661102294922, 'G_L1': 28.959156036376953, 'D': 0.0452435240149498, 'F': 0.009862104430794716}\n",
      "Epoch/total_steps/alpha-beta: 10/16300/1-1 {'G_GAN': 7.725302696228027, 'G_L1': 22.832731246948242, 'D': 0.1762731969356537, 'F': 0.010282410308718681}\n",
      "Epoch/total_steps/alpha-beta: 10/16400/1-1 {'G_GAN': 7.675027847290039, 'G_L1': 37.1957893371582, 'D': 0.07404058426618576, 'F': 0.004590428434312344}\n",
      "Epoch/total_steps/alpha-beta: 10/16500/1-1 {'G_GAN': 8.026204109191895, 'G_L1': 64.67173767089844, 'D': 0.05610287934541702, 'F': 0.011983966454863548}\n",
      "Epoch/total_steps/alpha-beta: 10/16600/1-1 {'G_GAN': 8.001333236694336, 'G_L1': 39.6786994934082, 'D': 0.02330709621310234, 'F': 0.005099699832499027}\n",
      "保存模型 Epoch 10, iters 16610 在 D:\\BaiduNetdiskWorkspace\\result\\CSA-256\n",
      "Epoch/Epochs 10/499 花费时间：6475.059796094894s\n",
      "learning rate = 0.0002\n",
      "Epoch/total_steps/alpha-beta: 11/16700/1-1 {'G_GAN': 8.382673263549805, 'G_L1': 60.174591064453125, 'D': 0.1334056854248047, 'F': 0.004445503931492567}\n",
      "Epoch/total_steps/alpha-beta: 11/16800/1-1 {'G_GAN': 7.793785095214844, 'G_L1': 27.951732635498047, 'D': 0.1080295518040657, 'F': 0.0075932652689516544}\n",
      "Epoch/total_steps/alpha-beta: 11/16900/1-1 {'G_GAN': 8.311108589172363, 'G_L1': 29.596094131469727, 'D': 0.03652622550725937, 'F': 0.004142523743212223}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4fd6718a4f74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_gt_latent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdisplay_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mreal_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_current_visuals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\CSA.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_F\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\CSA.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSyn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnknowregion\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknownregion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMiddle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSyn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMiddle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_B\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\networks.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutermost\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# if it is the outermost, directly pass the input in.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mx_latter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mx_latter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mx_latter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\networks.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mx_latter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx_latter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\CSA_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 self.h, self.w)\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         return CSAFunction.apply(input, self.mask, self.shift_sz, self.stride,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriple_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonmask_point_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_point_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_offsets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                                  self.sp_x, self.sp_y)\n",
      "\u001b[1;32me:\\kaggle\\pytorch-book\\apps\\models\\CSAFunction.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, input, mask, shift_sz, stride, triple_w, flag, nonmask_point_idx, mask_point_idx, flatten_offsets, sp_x, sp_y)\u001b[0m\n\u001b[0;32m     67\u001b[0m                     \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_offsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_r_ch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                     \u001b[0mcorrect_ch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_r_ch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m                     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                         \u001b[0mknown_region\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknown_patch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_r_ch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练阶段\n",
    "start_epoch = 0\n",
    "total_steps = 0\n",
    "iter_start_time = time.time()\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_iter = 0\n",
    "    # 初始化数据集\n",
    "    trainset = loader.trainset() # 训练集\n",
    "    maskset = loader.maskset() # mask 数据集\n",
    "    for image, mask in zip(trainset, maskset):\n",
    "        mask = mask_op(mask)\n",
    "        total_steps += model.batch_size\n",
    "        epoch_iter += model.batch_size\n",
    "        # it not only sets the input data with mask,\n",
    "        #  but also sets the latent mask.\n",
    "        model.set_input(image, mask)\n",
    "        model.set_gt_latent()\n",
    "        model.optimize_parameters()\n",
    "        if total_steps % display_freq == 0:\n",
    "            real_A, real_B, fake_B = model.get_current_visuals()\n",
    "            # real_A=input, real_B=ground truth fake_b=output\n",
    "            pic = (torch.cat([real_A, real_B, fake_B], dim=0) + 1) / 2.0\n",
    "            image_name = f\"epoch{epoch}-{total_steps}-{alpha}.png\"\n",
    "            save_image(pic, image_save_dir/image_name, ncol=1)\n",
    "        if total_steps % 100 == 0:\n",
    "            errors = model.get_current_errors()\n",
    "            t = (time.time() - iter_start_time) / model.batch_size\n",
    "            print(\n",
    "                f\"Epoch/total_steps/alpha-beta: {epoch}/{total_steps}/{alpha}-{beta}\", dict(errors))\n",
    "    if epoch % save_epoch_freq == 0:\n",
    "        print(f'保存模型 Epoch {epoch}, iters {total_steps} 在 {model.save_dir}')\n",
    "        model.save(epoch)\n",
    "    print(\n",
    "        f'Epoch/Epochs {epoch}/{epochs-1} 花费时间：{time.time() - epoch_start_time}s')\n",
    "    model.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91729c9a28b52734f57b710b306c58b64be9d1e1e07c58fcc763d6d7bdf51c2c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
